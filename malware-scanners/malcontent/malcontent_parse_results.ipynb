{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from packaging import version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse a single JSON file\n",
    "def parse_json_file(file_path, project):\n",
    "    parsed_data = []\n",
    "    \n",
    "    # Load the JSON file\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "        \n",
    "        # Iterate over each file entry in the JSON data\n",
    "        for file_path, file_info in data.get(\"Files\", {}).items():\n",
    "            # Extract the common details\n",
    "            path = file_info.get(\"Path\", \"\")\n",
    "            sha256 = file_info.get(\"SHA256\", \"\")\n",
    "            size = file_info.get(\"Size\", 0)\n",
    "            risk_score = file_info.get(\"RiskScore\", 0)\n",
    "            syscalls = file_info.get(\"Syscalls\", [])\n",
    "            pledges = file_info.get(\"Pledge\", [])\n",
    "            meta = file_info.get(\"Meta\", {})\n",
    "            \n",
    "            # Extract behaviors if available\n",
    "            behaviors = file_info.get(\"Behaviors\", [])\n",
    "            for behavior in behaviors:\n",
    "                behavior_data = {\n",
    "                    \"FilePath\": path,\n",
    "                    \"project\": project,\n",
    "                    \"apk\": path.split('/')[3].split(' ')[0],\n",
    "                    \"version\": path.split('/')[3].split(' ')[0].split('-')[-2],\n",
    "                    \"SHA256\": sha256,\n",
    "                    \"Size\": size,\n",
    "                    \"RiskScore\": risk_score,\n",
    "                    \"Syscalls\": syscalls,\n",
    "                    \"Pledges\": pledges,\n",
    "                    \"Meta\": meta,\n",
    "                    \"BehaviorDescription\": behavior.get(\"Description\", \"\"),\n",
    "                    \"MatchStrings\": behavior.get(\"MatchStrings\", []),\n",
    "                    \"BehaviorRiskScore\": behavior.get(\"RiskScore\", 0),\n",
    "                    \"RiskLevel\": behavior.get(\"RiskLevel\", \"\"),\n",
    "                    \"RuleURL\": behavior.get(\"RuleURL\", \"\"),\n",
    "                    \"ID\": behavior.get(\"ID\", \"\"),\n",
    "                    \"RuleName\": behavior.get(\"RuleName\", \"\"),\n",
    "                    \"ReferenceURL\": behavior.get(\"ReferenceURL\", \"\")\n",
    "                }\n",
    "                parsed_data.append(behavior_data)\n",
    "    \n",
    "    return parsed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the base folder (current directory or script location)\n",
    "base_folder = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "\n",
    "projects = [\"0_controller-gen\", \"1_gobump\", \"2_logstash-exporter\", \"3_prometheus-beat-exporter\", \"4_cosign\", \"5_step\", \"6_go-swagger\", \"7_grafana-agent-operator\", \"8_terragrunt\", \"9_litestream\"]\n",
    "\n",
    "# Initialize an empty list to store all parsed data\n",
    "all_parsed_data = []\n",
    "for project in projects:\n",
    "    # Append 'malcontent-results' folder to the base path\n",
    "    folder_path = os.path.join(base_folder, f'datasets/dataset6_over_time/go/{project}/malcontent-scan')\n",
    "    # Iterate over each file in the folder and parse it\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".json\"):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            parsed_data = parse_json_file(file_path, project)\n",
    "            all_parsed_data.extend(parsed_data)\n",
    "\n",
    "# Convert the parsed data into a pandas DataFrame\n",
    "df = pd.DataFrame(all_parsed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by project, then version (parsed as a proper version)\n",
    "df_sorted = df.sort_values(by=['project', 'version'], key=lambda col: col if col.name == 'project' else col.map(version.parse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_alerts(prior_apk, current_apk, match_cols):\n",
    "    prior = df[df['apk']==prior_apk].reset_index(drop=True)\n",
    "    current = df[df['apk']==current_apk].reset_index(drop=True)\n",
    "\n",
    "    new_alerts = current.merge(prior[match_cols], \n",
    "                               how='left', \n",
    "                               indicator=True, on=match_cols).query('_merge == \"left_only\"').drop(columns='_merge')\n",
    "    \n",
    "    match_cols = match_cols + [\"MatchStrings\"]\n",
    "    \n",
    "    if len(new_alerts) > 0:\n",
    "        temp_alerts = new_alerts[match_cols].copy()\n",
    "        temp_alerts['prior_apk'] = prior_apk\n",
    "        temp_alerts['current_apk'] = current_apk\n",
    "        temp_alerts['new_alerts'] = len(new_alerts)\n",
    "    else:\n",
    "        temp_alerts = pd.DataFrame([[None]*len(match_cols) + [prior_apk,\n",
    "                                                              current_apk,\n",
    "                                                              len(new_alerts)]], \n",
    "                                                              columns=match_cols + ['prior_apk',\n",
    "                                                                                    'current_apk',\n",
    "                                                                                    'new_alerts'])\n",
    "        \n",
    "    return temp_alerts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by FilePath to calculate statistics for each file\n",
    "grouped_df = df.groupby('FilePath')\n",
    "alert_counts = df.groupby(['apk', 'project', 'version'])['RiskLevel'].value_counts().unstack(fill_value=0).reset_index(drop=False)\n",
    "alert_counts_sort = alert_counts.sort_values(by=['project', 'version'], key=lambda col: col if col.name == 'project' else col.map(version.parse)).reset_index(drop=True)\n",
    "alert_counts_filter = alert_counts_sort[~alert_counts_sort['apk'].str.contains('.spdx.json')]\n",
    "\n",
    "# set the prior apk for later use\n",
    "alert_counts_filter['prior_apk'] = alert_counts_filter.apply(\n",
    "    lambda row: alert_counts_filter.loc[row.name - 1, 'apk']\n",
    "    if row.name - 1 >= 0 and row['project'] == alert_counts_filter.loc[row.name - 1, 'project']\n",
    "    else None,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Calculate deltas only for rows where the APK base (project) is the same as the prior row\n",
    "alert_counts_filter['LOW_DELTA'] = alert_counts_filter.apply(\n",
    "    lambda row: row['LOW'] - alert_counts_filter.loc[row.name - 1, 'LOW']\n",
    "    if row.name - 1 >= 0 and row['project'] == alert_counts_filter.loc[row.name - 1, 'project']\n",
    "    else None,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "alert_counts_filter['MEDIUM_DELTA'] = alert_counts_filter.apply(\n",
    "    lambda row: row['MEDIUM'] - alert_counts_filter.loc[row.name - 1, 'MEDIUM']\n",
    "    if row.name - 1 >= 0 and row['project'] == alert_counts_filter.loc[row.name - 1, 'project']\n",
    "    else None,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# matching columns for alerts\n",
    "columns = ['RiskScore', 'BehaviorDescription', 'BehaviorRiskScore', 'RiskLevel', 'RuleURL', 'ID', 'RuleName']\n",
    "\n",
    "new_alerts = pd.DataFrame()\n",
    "\n",
    "for index, row in alert_counts_filter.iterrows():\n",
    "    if row['prior_apk'] != None:\n",
    "        temp_results = get_new_alerts(prior_apk = row['prior_apk'], \n",
    "                    current_apk = row['apk'], \n",
    "                    match_cols = columns)\n",
    "    \n",
    "        new_alerts = pd.concat([new_alerts, temp_results])\n",
    "\n",
    "print(\"wait\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
